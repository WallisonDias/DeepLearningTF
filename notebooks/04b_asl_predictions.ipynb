{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://sites.google.com/fat.uerj.br/livia/\"> <img src=\"../images/capa2.png\" alt=\"Header\" style=\"width: 800px;\"/> </a></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vnikoofard/DeepLearningTF/blob/main/notebooks/04b_asl_predictions.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implantando seu modelo (*Deploying*)\n",
    "Agora que temos um modelo bem treinado, é hora de usá-lo. Neste exercício, vamos expor novas imagens ao nosso modelo e detectar as letras corretas do alfabeto da língua de sinais. Vamos começar!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Carregue um modelo já treinado do disco\n",
    "* Reformatar imagens para um modelo treinado em imagens de um formato diferente\n",
    "* Realize inferência com novas imagens, nunca vistas pelo modelo treinado e avalie seu desempenho"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando o Modelo\n",
    "Agora que estamos em um novo notebook, vamos carregar o modelo salvo que treinamos. Nosso salvamento do exercício anterior criou uma pasta chamada \"asl_model\". Podemos carregar o modelo selecionando a mesma pasta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    %pip install wget\n",
    "    import wget\n",
    "    image_url_1 = 'https://raw.githubusercontent.com/vnikoofard/DeepLearningTF/main/data/asl_images/b.png'\n",
    "    image_url_2 = 'https://raw.githubusercontent.com/vnikoofard/DeepLearningTF/main/data/asl_images/a.png'\n",
    "    model_url = 'https://raw.githubusercontent.com/vnikoofard/DeepLearningTF/main/data/asl_model/asl_model.h5'\n",
    "    wget.download(image_url_1, 'b.png')\n",
    "    wget.download(image_url_2, 'a.png')\n",
    "    wget.download(model_url, 'asl_model.h5')\n",
    "    image_path = ''\n",
    "    model_path = ''\n",
    "\n",
    "else:\n",
    "    image_path = '../data/asl_images/'\n",
    "    model_path = '../data/asl_model/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 17:05:18.368416: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.386405: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.386779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.388755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.389094: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.389361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.490244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.490573: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.490837: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-05-26 17:05:18.491043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 732 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model(model_path + 'asl_model.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quiser ter certeza de que tudo está intacto, você pode ver o resumo do modelo novamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando uma imagem para o modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é hora de usar o modelo para fazer previsões sobre novas imagens que nunca foram vistas antes. Isso também é chamado de inferência. Fornecemos a você um conjunto de imagens na pasta data/asl_images. Tente abri-lo usando a navegação à esquerda e explore as imagens.\n",
    "\n",
    "Você notará que as imagens que temos têm uma resolução muito maior do que as imagens em nosso conjunto de dados. Eles também são coloridos. Lembre-se de que nossas imagens no conjunto de dados tinham 28x28 pixels e tons de cinza. É importante ter em mente que sempre que você fizer previsões com um modelo, a entrada deve corresponder à forma dos dados nos quais o modelo foi treinado. Para este modelo, o conjunto de dados de treinamento tinha a forma: (27455, 28, 28, 1). Isso correspondeu a 27455 imagens de 28 por 28 pixels cada uma com um canal de cor (escala de cinza)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mostrando as Imagens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando usamos nosso modelo para fazer previsões sobre novas imagens, será útil mostrar a imagem também. Podemos usar a biblioteca matplotlib para fazer isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_image(image_path):\n",
    "    image = mpimg.imread(image_path)\n",
    "    plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(image_path + 'b.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionando as Imagens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As imagens em nosso conjunto de dados tinham 28x28 pixels e tons de cinza. Precisamos ter certeza de passar o mesmo tamanho e imagens em tons de cinza para o nosso método de previsão. Existem algumas maneiras de editar imagens com Python, mas o Keras possui um utilitário integrado que funciona bem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "\n",
    "def load_and_scale_image(image_path):\n",
    "    image = image_utils.load_img(image_path, color_mode=\"grayscale\", target_size=(28,28))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_and_scale_image(image_path + 'b.png')\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparando a imagem para previsão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos uma imagem em escala de cinza de 28 x 28 pixels, estamos quase prontos para passá-la para nosso modelo para previsão. Primeiro, precisamos remodelar nossa imagem para corresponder à forma do conjunto de dados no qual o modelo foi treinado. Antes de podermos remodelar, precisamos converter nossa imagem em um formato mais rudimentar. Faremos isso com um utilitário keras chamado image_to_array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_utils.img_to_array(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos remodelar nossa imagem para prepará-la para previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Este reshape corresponde a 1 imagem de 28x28 pixels com um canal de cor\n",
    "image = image.reshape(1,28,28,1) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, devemos lembrar de normalizar nossos dados (tornando todos os valores entre 0-1), como fizemos com nosso dataset de treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image / 255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo previsões \n",
    "Ok, agora estamos prontos para prever! Isso é feito passando a imagem pré-processada para o método de previsão do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(image)\n",
    "print(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compreendendo a previsão"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previsões estão no formato de uma matriz de 24 comprimentos. Embora pareça um pouco diferente, este é o mesmo formato de nossas matrizes categóricas \"binarizadas\" de y_train e y_test. Cada elemento da matriz é uma probabilidade entre 0 e 1, representando a confiança para cada categoria. Vamos torná-lo um pouco mais legível. Podemos começar descobrindo qual elemento da matriz representa a maior probabilidade. Isso pode ser feito facilmente com a biblioteca numpy e a função [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.argmax(prediction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada elemento da matriz de predição representa uma possível letra do alfabeto da língua de sinais. Lembre-se de que j e z não são opções porque envolvem mover a mão e estamos lidando apenas com fotos estáticas. Vamos criar um mapeamento entre o índice da matriz de previsões e a letra correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O alfabeto não contém j ou z porque eles exigem movimento\n",
    "alphabet = \"abcdefghiklmnopqrstuvwxy\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos passar nosso índice de previsão para encontrar a letra correspondente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet[np.argmax(prediction)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício: Junte tudo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos colocar tudo em uma função para que possamos fazer previsões apenas a partir do arquivo de imagem. Implemente-o na função abaixo usando as funções e etapas acima. Se precisar de ajuda, você pode revelar a solução clicando nos três pontos abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_letter(file_path):\n",
    "    # Show image\n",
    "    FIXME\n",
    "    # Load and scale image\n",
    "    image = FIXME\n",
    "    # Convert to array\n",
    "    image = FIXME\n",
    "    # Reshape image\n",
    "    image = FIXME\n",
    "    # Normalize image\n",
    "    image = FIXME\n",
    "    # Make prediction\n",
    "    prediction = FIXME\n",
    "    # Convert prediction to letter\n",
    "    predicted_letter = FIXME\n",
    "    # Return prediction\n",
    "    return predicted_letter   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solução"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clique no '...' abaixo para ver a solução."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def predict_letter(file_path):\n",
    "    show_image(file_path)\n",
    "    image = load_and_scale_image(file_path)\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape(1,28,28,1) \n",
    "    image = image/255\n",
    "    prediction = model.predict(image)\n",
    "    # convert prediction to letter\n",
    "    predicted_letter = alphabet[np.argmax(prediction)]\n",
    "    return predicted_letter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_letter(image_path + 'b.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos também usar a função com a letra 'a' no conjunto de dados asl_images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_letter(image_path + 'a.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ótimo trabalho nesses exercícios! Você passou por todo o processo de treinamento de um modelo altamente preciso desde o início e, em seguida, usou o modelo para fazer previsões novas e valiosas. Se você tiver algum tempo, nós encorajamos você a tirar fotos com sua webcam, carregá-las na pasta data/asl_images e testar o modelo nelas. Para Mac, você pode usar o Photo Booth. No Windows, você pode selecionar o aplicativo Câmera na tela inicial. Esperamos que você experimente. É uma boa oportunidade para aprender um pouco de língua de sinais! Por exemplo, experimente as letras do seu nome.\n",
    "\n",
    "Podemos imaginar como esse modelo poderia ser usado em um aplicativo para ensinar a língua de sinais a alguém, ou mesmo ajudar alguém que não sabe falar a interagir com um computador. Se você estiver familiarizado com o desenvolvimento da Web, os modelos podem até ser usados no navegador com uma biblioteca chamada [TensorFlow.js](https://www.tensorflow.org/js)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resetar o ambiente\n",
    "Antes de prosseguir, execute a célula a seguir para resetar o ambiente. Isso é necessário para passar para o próximo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esperamos que você tenha gostado desses exercícios. Nas próximas seções, aprenderemos como aproveitar o aprendizado profundo quando não tivermos um conjunto de dados robusto disponível. Vejo você lá!\n",
    "Para aprender mais sobre inferência na borda, confira [este belo artigo](http://web.eecs.umich.edu/~mosharaf/Readings/FB-ML-Edge.pdf) sobre o tópico."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que estamos familiarizados com a construção de seus próprios modelos e entendemos como eles funcionam, voltaremos nossa atenção para a técnica muito poderosa de usar modelos pré-treinados para agilizar seu trabalho."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
