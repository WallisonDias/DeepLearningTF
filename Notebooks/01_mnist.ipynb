{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><a href=\"https://sites.google.com/fat.uerj.br/livia/\"> <img src=\"../images/capa2.png\" alt=\"Header\" style=\"width: 800px;\"/> </a></center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/vnikoofard/DeepLearningTF/blob/main/Notebooks/01_mnist.ipynb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classificação de imagens com o conjunto de dados MNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, faremos o \"Hello World\" do aprendizado profundo (*Deep Learning*): treinar um modelo de aprendizado profundo para classificar corretamente os dígitos escritos à mão."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Entenda como o aprendizado profundo pode resolver problemas que os métodos de programação tradicionais não podem\n",
    "* Aprenda sobre o [conjunto de dados de dígitos manuscritos MNIST](http://yann.lecun.com/exdb/mnist/)\n",
    "* Use a [API do Keras](https://keras.io/) para carregar o conjunto de dados MNIST e prepará-lo para treinamento\n",
    "* Crie uma rede neural simples para realizar a classificação de imagens\n",
    "* Treine a rede neural usando o conjunto de dados MNIST preparado\n",
    "* Observe o desempenho da rede neural treinada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Problema: Classificação de Imagens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na programação tradicional, o programador é capaz de articular regras e condições em seu código que seu programa pode usar para agir da maneira correta. Essa abordagem continua a funcionar excepcionalmente bem para uma grande variedade de problemas.\n",
    "\n",
    "A classificação de imagem, que pede a um programa para classificar corretamente uma imagem que nunca viu antes em sua classe correta, é quase impossível de resolver com técnicas de programação tradicionais. Como poderia um programador definir as regras e condições para classificar corretamente uma enorme variedade de imagens, especialmente levando em conta imagens que nunca viu?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Solução: Deep Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O aprendizado profundo se destaca no reconhecimento de padrões por tentativa e erro. Ao treinar uma rede neural profunda com dados suficientes e fornecer à rede feedback sobre seu desempenho por meio de treinamento, a rede pode identificar, apesar de uma grande quantidade de iterações, seu próprio conjunto de condições pelas quais pode agir da maneira correta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O conjunto de dados MNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na história do aprendizado profundo, a classificação precisa de imagens do [conjunto de dados MNIST] (http://yann.lecun.com/exdb/mnist/), uma coleção de 70.000 imagens em escala de cinza de dígitos manuscritos de 0 a 9, foi um grande desenvolvimento. Embora hoje o problema seja considerado trivial, fazer classificação de imagens com MNIST tornou-se uma espécie de \"Hello World\" para deep learning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui estão 40 das imagens incluídas no conjunto de dados MNIST:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/mnist1.png\" style=\"width: 600px;\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dados e rótulos de treinamento e validação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of preparing data for analysis is called [Data Engineering](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7). To learn more about the differences between training data and validation data (as well as test data), check out [this article](https://machinelearningmastery.com/difference-test-validation-datasets/) by Jason Brownlee.\n",
    "\n",
    "\n",
    "Ao trabalhar com imagens para aprendizado profundo, precisamos das próprias imagens, geralmente indicadas como `X`, e também dos [rótulos](https://developers.google.com/machine-learning/glossary#label) corretos para eles imagens, geralmente denotadas como 'Y'. Além disso, precisamos dos valores `X` e `Y` para *treinar* o modelo e, em seguida, um conjunto separado de valores `X` e `Y` para *validar* o desempenho do modelo após ele ter sido treinado. Portanto, precisamos de 4 segmentos de dados para o conjunto de dados MNIST:\n",
    "\n",
    "1. `x_train`: Imagens usadas para treinar a rede neural\n",
    "2. `y_train`: rótulos corretos para as imagens `x_train`, usados para avaliar as previsões do modelo durante o treinamento\n",
    "3. `x_valid`: Imagens reservadas para validar o desempenho do modelo depois de treinado\n",
    "4. `y_valid`: rótulos corretos para as imagens `x_valid`, usados para avaliar as previsões do modelo depois de treinado\n",
    "\n",
    "O processo de preparação de dados para análise é chamado de [Engenharia de Dados](https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7). Para saber mais sobre as diferenças entre dados de treinamento e dados de validação (bem como dados de teste), confira [este artigo](https://machinelearningmastery.com/difference-test-validation-datasets/) de Jason Brownlee."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os dados na memória (com Keras)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many [deep learning frameworks](https://developer.nvidia.com/deep-learning-frameworks), each with their own merits. In this workshop we will be working with [Tensorflow 2](https://www.tensorflow.org/tutorials/quickstart/beginner), and specifically with the [Keras API](https://keras.io/). Keras has many useful built in functions designed for the computer vision tasks. It is also a legitimate choice for deep learning in a professional setting due to its [readability](https://blog.pragmaticengineer.com/readable-code/) and efficiency, though it is not alone in this regard, and it is worth investigating a variety of frameworks when beginning a deep learning project.\n",
    "\n",
    "One of the many helpful features that Keras provides are modules containing many helper methods for [many common datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets), including MNIST.\n",
    "\n",
    "We will begin by loading the Keras dataset module for MNIST:\n",
    "\n",
    "Existem muitos [frameworks de aprendizado profundo](https://developer.nvidia.com/deep-learning-frameworks), cada um com seus próprios méritos. Neste workshop, trabalharemos com [Tensorflow 2](https://www.tensorflow.org/tutorials/quickstart/beginner) e especificamente com a [API do Keras](https://keras.io/). O Keras tem muitas funções integradas úteis projetadas para as tarefas de visão computacional. Também é uma escolha legítima para aprendizado profundo em um ambiente profissional devido à sua [legibilidade](https://blog.pragmaticengineer.com/readable-code/) e eficiência, embora não seja o único a esse respeito, e é vale a pena investigar uma variedade de estruturas ao iniciar um projeto de aprendizado profundo.\n",
    "\n",
    "Um dos muitos recursos úteis que o Keras fornece são módulos contendo muitos métodos auxiliares para [muitos conjuntos de dados comuns](https://www.tensorflow.org/api_docs/python/tf/keras/datasets), incluindo MNIST.\n",
    "\n",
    "Começaremos carregando o módulo de conjunto de dados Keras para MNIST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o módulo `mnist`, podemos facilmente carregar os dados MNIST, já particionados em imagens e rótulos para treinamento e validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and validation sets\n",
    "(x_train, y_train), (x_valid, y_valid) = mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando os dados MNIST"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afirmamos acima que o conjunto de dados MNIST continha 70.000 imagens em escala de cinza de dígitos manuscritos. Ao executar as células a seguir, podemos ver que Keras particionou 60.000 dessas imagens para treinamento e 10.000 para validação (após o treinamento) e também que cada imagem em si é um array 2D com as dimensões 28x28:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além disso, podemos ver que essas imagens de 28 x 28 são representadas como uma coleção de valores inteiros de 8 bits positivos entre 0 e 255, os valores correspondentes ao valor de escala de cinza de um pixel em que `0` é preto, `255` é branco e todos os outros os valores neste intervalo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando [Matplotlib](https://matplotlib.org/), podemos renderizar uma dessas imagens em tons de cinza em nosso conjunto de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = x_train[0]\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desta forma, podemos ver que esta é uma imagem de 28x28 pixels de um 5. Ou é um 3? A resposta está nos dados `y_train`, que contém rótulos corretos para os dados. Vamos dar uma olhada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os dados para treinamento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No aprendizado profundo, é comum que os dados precisem ser transformados para ficarem no estado ideal para o treinamento. Para este problema específico de classificação de imagens, existem 3 tarefas que devemos realizar com os dados em preparação para o treinamento:\n",
    "1. Achate (*flatten*) os dados da imagem para simplificar a entrada da imagem no modelo\n",
    "2. Normalize os dados da imagem, para facilitar o trabalho com os valores de entrada da imagem para o modelo\n",
    "3. Categorize os rótulos, para facilitar o trabalho com os valores do rótulo para o modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening the Image Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora seja possível para um modelo de aprendizado profundo aceitar uma imagem bidimensional (no nosso caso, 28 x 28 pixels), vamos simplificar as coisas para começar e [reformar (*reshape*)](https://www.tensorflow.org/api_docs/python /tf/reshape) cada imagem em uma única matriz de 784 pixels contínuos (nota: 28x28 = 784). Isso também é chamado de nivelamento da imagem.\n",
    "\n",
    "Aqui nós realizamos isso usando o método auxiliar `reshape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_valid = x_valid.reshape(10000, 784)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos confirmar que os dados da imagem foram reformulados e agora são uma coleção de matrizes 1D contendo 784 valores de pixel cada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando os dados da imagem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos de aprendizado profundo são melhores para lidar com números de ponto flutuante entre 0 e 1 (falaremos mais sobre esse tópico posteriormente). Converter valores inteiros em valores de ponto flutuante entre 0 e 1 é chamado de [normalização](https://developers.google.com/machine-learning/glossary#normalization), e uma abordagem simples que usaremos aqui para normalizar os dados será para dividir todos os valores de pixel (que, se você se lembra, estão entre 0 e 255) por 255:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_valid = x_valid / 255 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora podemos ver que os valores são todos valores de ponto flutuante entre `0.0` e `1.0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificação categórica (*Categorical Encoding*)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considere por um momento, se perguntássemos, quanto é 7 - 2? Afirmar que a resposta foi 4 é mais próximo do que afirmar que a resposta foi 9. No entanto, para este problema de classificação de imagens, não queremos que a rede neural aprenda esse tipo de raciocínio: queremos apenas que ela selecione a categoria correta e entenda que se tivermos uma imagem do número 5, adivinhar o 4 é tão ruim quanto adivinhar o 9.\n",
    "\n",
    "Tal como está, os rótulos das imagens são inteiros entre 0 e 9. Como esses valores representam um intervalo numérico, o modelo pode tentar tirar algumas conclusões sobre seu desempenho com base no quão próximo da categoria numérica correta ele supõe.\n",
    "\n",
    "Portanto, faremos algo com nossos dados chamado codificação categórica (*Categorical Encoding*). Esse tipo de transformação modifica os dados para que cada valor seja uma coleção de todas as categorias possíveis, com a categoria real em que esse valor específico é definido como verdadeiro.\n",
    "\n",
    "Como um exemplo simples, considere se tivéssemos 3 categorias: vermelho, azul e verde. Para uma determinada cor, 2 dessas categorias seriam falsas e a outra seria verdadeira:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Cor Real| É vermelho? | É azul? | é verde?|\n",
    "|------------|---------|----------|----------|\n",
    "|Vermelho|Verdadeiro|Falso|Falso|\n",
    "|Verde|Falso|Falso|Verdadeiro|\n",
    "|Azul|Falso|Verdadeiro|Falso|\n",
    "|Verde|Falso|Falso|Verdadeiro|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em vez de usar \"Verdadeiro\" ou \"Falso\", poderíamos representar o mesmo usando binário, 0 ou 1:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Cor Real| É vermelho? | É azul? | é verde?|\n",
    "|------------|---------|----------|----------|\n",
    "|Vermelho|1|0|0|\n",
    "|Verde|0|0|1|\n",
    "|Azul|0|1|0|\n",
    "|Verde|0|0|1|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É isso que é a codificação categórica, transformando valores que devem ser entendidos como rótulos categóricos em uma representação que torna sua natureza categórica explícita para o modelo. Assim, se estivéssemos usando esses valores para treinamento, converteríamos..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "values = ['red, green, blue, green']\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... que uma rede neural teria muita dificuldade em entender, em vez de:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "values = [\n",
    "    [1, 0, 0],\n",
    "    [0, 0, 1],\n",
    "    [0, 1, 0],\n",
    "    [0, 0, 1]\n",
    "]\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificando categoricamente os rótulos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Keras fornece um utilitário para [codificar valores categoricamente](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) e aqui o usamos para realizar codificação categórica para os rótulos de treinamento e validação:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "num_categories = 10\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_categories)\n",
    "y_valid = keras.utils.to_categorical(y_valid, num_categories)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui estão os primeiros 10 valores dos rótulos de treinamento, que você pode ver agora foram codificados categoricamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0:9]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando o modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com os dados preparados para o treinamento, agora é hora de criar o modelo que vamos treinar com os dados. Este primeiro modelo básico será composto por várias *camadas* e será composto por 3 partes principais:\n",
    "\n",
    "1. Uma camada de entrada, que receberá dados em algum formato esperado\n",
    "2. Várias [camadas ocultas](https://developers.google.com/machine-learning/glossary#hidden-layer), cada uma composta por muitos *neurônios*. Cada [neurônio](https://developers.google.com/machine-learning/glossary#neuron) terá a capacidade de afetar a estimativa da rede com seus *pesos*, que são valores que serão atualizados ao longo de muitas iterações conforme o rede obtém feedback sobre seu desempenho e aprende\n",
    "3. Uma camada de saída, que representará a estimativa da rede para uma determinada imagem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciando o Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para começar, usaremos a classe de modelo [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) do Keras para instanciar uma instância de um modelo que terá uma série de camadas que os dados passar em sequência:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a Camada de Entrada"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, adicionaremos a camada de entrada. Essa camada será *densamente conectada*, o que significa que cada neurônio nela e seus pesos afetarão todos os neurônios da próxima camada. Para fazer isso com o Keras, usamos a classe de camada [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) do Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O argumento `units` especifica o número de neurônios na camada. Vamos usar `512` que escolhemos na experimentação. Escolher o número correto de neurônios é o que coloca a \"ciência\" na \"ciência de dados\", pois é uma questão de capturar a complexidade estatística do conjunto de dados. Tente brincar com esse valor mais tarde para ver como isso afeta o treinamento e começar a desenvolver uma noção do que esse número significa.\n",
    "\n",
    "Aprenderemos mais sobre funções de ativação mais tarde, mas por enquanto, usaremos a função de ativação `relu`, que em resumo, ajudará nossa rede a aprender como fazer suposições mais sofisticadas sobre dados do que se fosse necessário fazer suposições com base em alguma função estritamente linear.\n",
    "\n",
    "O valor `input_shape` especifica a forma dos dados recebidos que, em nossa situação, é uma matriz 1D de 784 valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=512, activation='relu', input_shape=(784,)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a Camada Oculta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos adicionar uma camada adicional densamente conectada. Mais uma vez, muito mais será dito sobre isso mais tarde, mas por enquanto saiba que essas camadas fornecem à rede mais parâmetros para contribuir com suas suposições e, portanto, oportunidades mais sutis para um aprendizado preciso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 512, activation='relu'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando a Camada de Saída"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, adicionaremos uma camada de saída. Esta camada usa a função de ativação `softmax` que resultará em cada um dos valores da camada sendo uma probabilidade entre 0 e 1 e resultará em todas as saídas da camada somando 1. Neste caso, como a rede deve fazer uma adivinhe sobre uma única imagem pertencente a 1 das 10 categorias possíveis, haverá 10 saídas. Cada saída fornece o palpite do modelo (uma probabilidade) de que a imagem pertence a essa classe específica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 10, activation='softmax'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumindo o Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras fornece o método de instância do modelo [summary](https://www.tensorflow.org/api_docs/python/tf/summary) que imprimirá um resumo legível de um modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe o número de parâmetros treináveis. Cada um deles pode ser ajustado durante o treinamento e contribuirá para as suposições do modelo treinado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilando o Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novamente, mais detalhes estão por vir, mas a etapa final que precisamos fazer antes de podermos realmente treinar nosso modelo com dados é [compilar](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential #compilar). Aqui especificamos uma [função de perda (*loss*)](https://developers.google.com/machine-learning/glossary#loss) que será usada para o modelo entender o desempenho dele durante o treinamento. Também especificamos que gostaríamos de rastrear `precisão` enquanto o modelo treina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o Modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que preparamos os dados de treinamento e validação e um modelo, é hora de treinar nosso modelo com nossos dados de treinamento e verificá-lo com seus dados de validação.\n",
    "\n",
    "\"Treinar um modelo com dados\" geralmente também é chamado de \"ajustar um modelo aos dados\". Colocado desta forma, ele destaca que a forma do modelo muda ao longo do tempo para entender com mais precisão os dados que estão sendo fornecidos.\n",
    "\n",
    "Ao ajustar (treinar) um modelo com Keras, usamos o método [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) do modelo. Ele espera os seguintes argumentos:\n",
    "\n",
    "* Os dados de treinamento\n",
    "* Os rótulos dos dados de treinamento\n",
    "* O número de vezes que ele deve treinar em todo o conjunto de dados de treinamento (chamado de *época*)\n",
    "* Os dados de validação ou teste e seus rótulos\n",
    "\n",
    "Execute a célula abaixo para treinar o modelo. Discutiremos sua saída após a conclusão do treinamento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x_train, y_train, epochs=5, verbose=1, validation_data=(x_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precisão de observação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cada uma das 5 épocas, observe as pontuações `accuracy` e `val_accuracy`. `precisão` indica o desempenho do modelo para a época em todos os dados de treinamento. `val_accuracy` indica o desempenho do modelo nos dados de validação, que, se você se lembra, não foi usado para treinar o modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A modelo mandou muito bem! A precisão atingiu rapidamente perto de 100%, assim como a precisão da validação. Agora temos um modelo que pode ser usado para detectar e classificar com precisão imagens manuscritas.\n",
    "\n",
    "O próximo passo seria usar esse modelo para classificar novas imagens manuscritas ainda não vistas. Isso é chamado de [inferência](https://blogs.nvidia.com/blog/2016/08/22/difference-deep-learning-training-inference-ai/). Exploraremos o processo de inferência em um exercício posterior."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale a pena reservar um momento para apreciar o que fizemos aqui. Historicamente, os sistemas especialistas que foram construídos para realizar esse tipo de tarefa eram extremamente complicados, e as pessoas passavam suas carreiras construindo-os (confira as referências na [página oficial do MNIST](http://yann.lecun.com/exdb/ mnist/) e os marcos dos anos foram alcançados).\n",
    "\n",
    "O MNIST não é útil apenas por sua influência histórica na Visão Computacional, mas também é uma ótima [referência](http://www.cs.toronto.edu/~serailhydra/publications/tbd-iiswc18.pdf) e ferramenta de depuração. Está tendo problemas para fazer uma nova arquitetura sofisticada de aprendizado de máquina funcionar? Compare com o MNIST. Se não conseguir aprender neste conjunto de dados, é provável que não aprenda em imagens e conjuntos de dados mais complicados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear the Memory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, please execute the following cell to clear up the GPU memory. This is required to move on to the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta seção, você aprendeu como construir e treinar uma rede neural simples para classificação de imagens. Na próxima seção, você será solicitado a construir sua própria rede neural e realizar a preparação de dados para resolver um problema de classificação de imagem diferente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ☆ Exercício Bônus ☆\n",
    "\n",
    "Tem tempo de sobra? Na próxima seção, falaremos sobre como chegamos a alguns dos números acima, mas podemos tentar imaginar como seria ser um pesquisador desenvolvendo as técnicas comumente usadas hoje.\n",
    "\n",
    "Em última análise, cada neurônio está tentando ajustar uma linha a alguns dados. Abaixo, temos alguns pontos de dados e uma linha desenhada aleatoriamente usando a equação [y = mx + b](https://www.mathsisfun.com/equation_of_line.html).\n",
    "\n",
    "Tente alterar o `m` e o `b` para encontrar a menor perda possível. Como você encontrou a melhor linha? Você pode fazer um programa para seguir sua estratégia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "m = -2  # -2 to start, change me please\n",
    "b = 40  # 40 to start, change me please\n",
    "\n",
    "# Sample data\n",
    "x = np.array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9])\n",
    "y = np.array([10, 20, 25, 30, 40, 45, 40, 50, 60, 55])\n",
    "y_hat = x * m + b\n",
    "\n",
    "plt.plot(x, y, '.')\n",
    "plt.plot(x, y_hat, '-')\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss:\", np.sum((y - y_hat)**2)/len(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenha uma ideia? Excelente! Por favor, desligue o kernel antes de prosseguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os._exit(00)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
